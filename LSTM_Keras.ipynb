{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "reHLNiQ70_jZ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "38abFt4bibY4"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./data/splited_train.csv')\n",
    "test_data = pd.read_csv('./data/splited_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "As7F7E6fjqUC"
   },
   "outputs": [],
   "source": [
    "train_input = list(train_data['question_text'])\n",
    "train_label = list(train_data['target'])\n",
    "\n",
    "test_input = list(test_data['question_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q7OD7O3ojudW",
    "outputId": "9584cfb1-853f-47fe-d655-c2e13ba3fc9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#remove all the stop words for the \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop=stopwords.words('english') \n",
    "\n",
    "def remove_stop_words(x):\n",
    "    for word in stop:\n",
    "        token = \" \" + word + \" \"\n",
    "        if (x.find(token) != -1):\n",
    "            x = x.replace(token, \" \")\n",
    "    return x\n",
    "\n",
    "# train_input_rsw = list(map(remove_stop_words, train_input))\n",
    "# test_input_rsw = list(map(remove_stop_words, test_input))\n",
    "train_input_rsw=train_input\n",
    "test_input_rsw =test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "aWmBKPD1llau"
   },
   "outputs": [],
   "source": [
    "max_features=100000\n",
    "embed_size = 300 \n",
    "max_length = 70 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "bF_hLNh3loF9"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wn5jUZJInZPx"
   },
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(\"./data/embeddings/glove.840B.300d/glove.840B.300d.txt\",'r') as f:\n",
    "    for line in f:\n",
    "        \n",
    "        word,coefs=get_coefs(*line.split(\" \"))\n",
    "        #coefs = np.asarray(coefs, dtype='float32')\n",
    "        embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bp7o_4rvnhMh"
   },
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer(num_words=max_features)\n",
    "\n",
    "tokenizer.fit_on_texts(train_input_rsw)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "n_words=min(max_features,len(word_index))\n",
    "\n",
    "embedding_matrix = np.zeros((n_words+1, embed_size))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: \n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: \n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wusi8R48nB_o",
    "outputId": "53008aeb-407f-4828-f929-97285f379ec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1044897, 70)\n",
      "(261225, 70)\n"
     ]
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(train_input_rsw)\n",
    "\n",
    "train_input_padded = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "print(train_input_padded.shape)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(test_input_rsw)\n",
    "test_input_padded = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "print(test_input_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QUclEQCBolmj"
   },
   "outputs": [],
   "source": [
    "train_text, cv_text, train_target, cv_target = train_test_split(train_input_padded, train_label, test_size = 0.1, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TTS6lJ_Zo2Ba"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,Bidirectional,LSTM,Dropout,Conv1D,MaxPooling1D,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JpC5AcyLo4Ku",
    "outputId": "d0670971-eb97-4cbf-a023-cf306ee41ebf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 70, 300)           30000300  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 70, 256)           570368    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 70, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 66, 100)           128100    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 16, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 30,816,145\n",
      "Trainable params: 815,845\n",
      "Non-trainable params: 30,000,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#just lstm with \n",
    "lstm=Sequential()\n",
    "lstm.add(Embedding(n_words+1,embed_size,input_length=max_length,weights=[embedding_matrix], trainable=False))\n",
    "lstm.add(LSTM(256,return_sequences=True))\n",
    "lstm.add(Dropout(0.2))\n",
    "lstm.add(Conv1D(100,5,activation='relu'))\n",
    "lstm.add(MaxPooling1D(pool_size=4))\n",
    "lstm.add(LSTM(128))\n",
    "lstm.add(Dropout(0.4))\n",
    "lstm.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "lstm.summary()\n",
    "\n",
    "lstm.compile(loss='binary_crossentropy',optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "jIBvkjWGqzQH"
   },
   "outputs": [],
   "source": [
    "# del embeddings_index\n",
    "# import gc\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rEdAmpA6q1aF",
    "outputId": "c3bcde49-be4a-4127-fba1-7df7d6f1ab2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "919/919 [==============================] - 121s 96ms/step - loss: 0.2033 - acc: 0.9365 - val_loss: 0.1138 - val_acc: 0.9554\n",
      "Epoch 2/5\n",
      "919/919 [==============================] - 87s 95ms/step - loss: 0.1117 - acc: 0.9559 - val_loss: 0.1070 - val_acc: 0.9581\n",
      "Epoch 3/5\n",
      "919/919 [==============================] - 87s 95ms/step - loss: 0.1043 - acc: 0.9590 - val_loss: 0.1043 - val_acc: 0.9590\n",
      "Epoch 4/5\n",
      "919/919 [==============================] - 87s 95ms/step - loss: 0.0979 - acc: 0.9611 - val_loss: 0.1015 - val_acc: 0.9599\n",
      "Epoch 5/5\n",
      "919/919 [==============================] - 87s 95ms/step - loss: 0.0936 - acc: 0.9630 - val_loss: 0.1013 - val_acc: 0.9596\n"
     ]
    }
   ],
   "source": [
    "history=lstm.fit(np.array(train_text), np.array(train_target), epochs = 5, validation_data=(np.array(cv_text),np.array(cv_target)), batch_size=1024,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AXVFNv80xJ9A",
    "outputId": "c86823ae-895e-4de2-a935-a092ffee1bc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold 0.1 is 0.592470854090699\n",
      "F1 score at threshold 0.11 is 0.6003453869904234\n",
      "F1 score at threshold 0.12 is 0.6092297831428266\n",
      "F1 score at threshold 0.13 is 0.6162291428882005\n",
      "F1 score at threshold 0.14 is 0.6223154640313586\n",
      "F1 score at threshold 0.15 is 0.6285906642728905\n",
      "F1 score at threshold 0.16 is 0.6329675328367544\n",
      "F1 score at threshold 0.17 is 0.6374892024186583\n",
      "F1 score at threshold 0.18 is 0.6413334887516028\n",
      "F1 score at threshold 0.19 is 0.6426847218133647\n",
      "F1 score at threshold 0.2 is 0.6457217660359397\n",
      "F1 score at threshold 0.21 is 0.6490225563909774\n",
      "F1 score at threshold 0.22 is 0.651505016722408\n",
      "F1 score at threshold 0.23 is 0.6548204623708804\n",
      "F1 score at threshold 0.24 is 0.65647906572245\n",
      "F1 score at threshold 0.25 is 0.6590139254798644\n",
      "F1 score at threshold 0.26 is 0.6612974824021816\n",
      "F1 score at threshold 0.27 is 0.6644390181210642\n",
      "F1 score at threshold 0.28 is 0.6663628670008463\n",
      "F1 score at threshold 0.29 is 0.6698324759266587\n",
      "F1 score at threshold 0.3 is 0.6729370955906877\n",
      "F1 score at threshold 0.31 is 0.6735688185140072\n",
      "F1 score at threshold 0.32 is 0.674205043859649\n",
      "F1 score at threshold 0.33 is 0.674977491516033\n",
      "F1 score at threshold 0.34 is 0.6747865042699146\n",
      "F1 score at threshold 0.35 is 0.6745319675026491\n",
      "F1 score at threshold 0.36 is 0.6753561253561253\n",
      "F1 score at threshold 0.37 is 0.6753675152384367\n",
      "F1 score at threshold 0.38 is 0.6761663652802894\n",
      "F1 score at threshold 0.39 is 0.6764341424302062\n",
      "F1 score at threshold 0.4 is 0.6768010575016523\n",
      "F1 score at threshold 0.41 is 0.6761897712974613\n",
      "F1 score at threshold 0.42 is 0.6752665722168368\n",
      "F1 score at threshold 0.43 is 0.6745757621264454\n",
      "F1 score at threshold 0.44 is 0.6737320211960636\n",
      "F1 score at threshold 0.45 is 0.6726580350342726\n",
      "F1 score at threshold 0.46 is 0.673196112939016\n",
      "F1 score at threshold 0.47 is 0.671236041586446\n",
      "F1 score at threshold 0.48 is 0.6708488228004956\n",
      "F1 score at threshold 0.49 is 0.6700950599968832\n",
      "F1 score at threshold 0.5 is 0.6691741106409654\n",
      "Best value [0.4, 0.6768010575016523]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "cv_predictions = lstm.predict(cv_text, batch_size=512)\n",
    "\n",
    "thresholds = []\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    result = f1_score(cv_target, (cv_predictions>thresh).astype(int))\n",
    "    thresholds.append([thresh, result])\n",
    "    print(\"F1 score at threshold {} is {}\".format(thresh, result))\n",
    "\n",
    "thresholds.sort(key=lambda x: x[1], reverse=True)\n",
    "print(\"Best value {}\".format(thresholds[0]))\n",
    "best_thresh = thresholds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9LHDWU0GxVVu",
    "outputId": "39f2b7a8-d8eb-4b12-b7fc-162b838fbaad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6747002398081535\n"
     ]
    }
   ],
   "source": [
    "#run on test set with best threshold\n",
    "total_predictions=lstm.predict(test_input_padded, batch_size=512)\n",
    "test_labels=list(test_data['target'])\n",
    "predictions1 = (total_predictions>best_thresh).astype(int)\n",
    "res=f1_score(test_labels, predictions1[:,0])\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "LSTM_Keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
