{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "reHLNiQ70_jZ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "38abFt4bibY4"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./data/splited_train.csv')\n",
    "test_data = pd.read_csv('./data/splited_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "As7F7E6fjqUC"
   },
   "outputs": [],
   "source": [
    "train_input = list(train_data['question_text'])\n",
    "train_label = list(train_data['target'])\n",
    "\n",
    "test_input = list(test_data['question_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 425,
     "status": "ok",
     "timestamp": 1622310055399,
     "user": {
      "displayName": "Zhaoyi Huang",
      "photoUrl": "",
      "userId": "07120073316656133052"
     },
     "user_tz": 420
    },
    "id": "q7OD7O3ojudW",
    "outputId": "6c2acc97-771c-4a3d-edeb-bd314fb7ea18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#remove all the stop words for the \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop=stopwords.words('english') \n",
    "\n",
    "def remove_stop_words(x):\n",
    "    for word in stop:\n",
    "        token = \" \" + word + \" \"\n",
    "        if (x.find(token) != -1):\n",
    "            x = x.replace(token, \" \")\n",
    "    return x\n",
    "\n",
    "# train_input_rsw = list(map(remove_stop_words, train_input))\n",
    "# test_input_rsw = list(map(remove_stop_words, test_input))\n",
    "train_input_rsw=train_input\n",
    "test_input_rsw=test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aWmBKPD1llau"
   },
   "outputs": [],
   "source": [
    "max_features=95000\n",
    "embed_size = 300 \n",
    "max_length = 60 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wn5jUZJInZPx"
   },
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(\"./data/embeddings/glove.840B.300d/glove.840B.300d.txt\",'r') as f:\n",
    "    for line in f:\n",
    "        \n",
    "        word,coefs=get_coefs(*line.split(\" \"))\n",
    "        #coefs = np.asarray(coefs, dtype='float32')\n",
    "        embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24893,
     "status": "ok",
     "timestamp": 1622310208827,
     "user": {
      "displayName": "Zhaoyi Huang",
      "photoUrl": "",
      "userId": "07120073316656133052"
     },
     "user_tz": 420
    },
    "id": "bp7o_4rvnhMh",
    "outputId": "46a86c8e-fbc1-462c-d507-95bf4e177b1e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "tokenizer=Tokenizer(num_words=max_features)\n",
    "\n",
    "tokenizer.fit_on_texts(train_input_rsw)\n",
    "\n",
    "\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "n_words=min(max_features,len(word_index))\n",
    "\n",
    "# embedding_matrix = np.zeros((n_words+1, embed_size))\n",
    "\n",
    "# for word, i in word_index.items():\n",
    "#     if i >= max_features: \n",
    "#         continue\n",
    "#     embedding_vector = embeddings_index.get(word)\n",
    "#     if embedding_vector is not None: \n",
    "#         embedding_matrix[i] = embedding_vector\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22500,
     "status": "ok",
     "timestamp": 1622310231315,
     "user": {
      "displayName": "Zhaoyi Huang",
      "photoUrl": "",
      "userId": "07120073316656133052"
     },
     "user_tz": 420
    },
    "id": "wusi8R48nB_o",
    "outputId": "d7bc2518-f077-4f82-d69d-bb7b24a1d3c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1044897, 60)\n",
      "(261225, 60)\n"
     ]
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(train_input_rsw)\n",
    "\n",
    "train_input_padded = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "print(train_input_padded.shape)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(test_input_rsw)\n",
    "test_input_padded = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "print(test_input_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QUclEQCBolmj"
   },
   "outputs": [],
   "source": [
    "train_text, cv_text, train_target, cv_target = train_test_split(train_input_padded, train_label, test_size = 0.1, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CJyYFMrnzWDr"
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/qqgeogor/keras-lstm-attention-glove840b-lb-0-043\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        self.W = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 initializer=self.init,\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_shape[1],),\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     initializer='zero',\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TTS6lJ_Zo2Ba"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding,Bidirectional,LSTM,Dropout,Conv1D,MaxPooling1D,Dense\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JpC5AcyLo4Ku"
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(max_length,))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "x=Dropout(0.4)(x)\n",
    "x = Attention(max_length)(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=1e-3), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jIBvkjWGqzQH"
   },
   "outputs": [],
   "source": [
    "# del embeddings_index\n",
    "# import gc\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 456943,
     "status": "ok",
     "timestamp": 1622310695942,
     "user": {
      "displayName": "Zhaoyi Huang",
      "photoUrl": "",
      "userId": "07120073316656133052"
     },
     "user_tz": 420
    },
    "id": "rEdAmpA6q1aF",
    "outputId": "7fa66437-5f89-4476-b803-6db9bfde4bb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "919/919 [==============================] - 111s 96ms/step - loss: 0.1467 - acc: 0.9458 - val_loss: 0.1104 - val_acc: 0.9562\n",
      "Epoch 2/5\n",
      "919/919 [==============================] - 87s 94ms/step - loss: 0.1074 - acc: 0.9573 - val_loss: 0.1047 - val_acc: 0.9584\n",
      "Epoch 3/5\n",
      "919/919 [==============================] - 87s 94ms/step - loss: 0.1007 - acc: 0.9599 - val_loss: 0.1021 - val_acc: 0.9594\n",
      "Epoch 4/5\n",
      "919/919 [==============================] - 86s 94ms/step - loss: 0.0952 - acc: 0.9619 - val_loss: 0.1011 - val_acc: 0.9599\n",
      "Epoch 5/5\n",
      "919/919 [==============================] - 86s 94ms/step - loss: 0.0907 - acc: 0.9634 - val_loss: 0.0996 - val_acc: 0.9606\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(np.array(train_text), np.array(train_target), epochs =5, validation_data=(np.array(cv_text),np.array(cv_target)), batch_size=1024,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8911,
     "status": "ok",
     "timestamp": 1622310704844,
     "user": {
      "displayName": "Zhaoyi Huang",
      "photoUrl": "",
      "userId": "07120073316656133052"
     },
     "user_tz": 420
    },
    "id": "AXVFNv80xJ9A",
    "outputId": "a33d0003-4ead-4ffa-cbff-2342f08e2d18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold 0.1 is 0.6206101843722563\n",
      "F1 score at threshold 0.11 is 0.6273128738330818\n",
      "F1 score at threshold 0.12 is 0.6340100364963503\n",
      "F1 score at threshold 0.13 is 0.6377113736391012\n",
      "F1 score at threshold 0.14 is 0.6441833137485311\n",
      "F1 score at threshold 0.15 is 0.6486486486486487\n",
      "F1 score at threshold 0.16 is 0.6531798909751665\n",
      "F1 score at threshold 0.17 is 0.6567916410571604\n",
      "F1 score at threshold 0.18 is 0.659155981575999\n",
      "F1 score at threshold 0.19 is 0.6624653390471388\n",
      "F1 score at threshold 0.2 is 0.665561224489796\n",
      "F1 score at threshold 0.21 is 0.6678719008264462\n",
      "F1 score at threshold 0.22 is 0.6696673189823875\n",
      "F1 score at threshold 0.23 is 0.6693936794880253\n",
      "F1 score at threshold 0.24 is 0.6714181043095984\n",
      "F1 score at threshold 0.25 is 0.6723708145253655\n",
      "F1 score at threshold 0.26 is 0.6733818825290956\n",
      "F1 score at threshold 0.27 is 0.6738070717473394\n",
      "F1 score at threshold 0.28 is 0.675949016348019\n",
      "F1 score at threshold 0.29 is 0.677705582337735\n",
      "F1 score at threshold 0.3 is 0.679181369089626\n",
      "F1 score at threshold 0.31 is 0.680587229190422\n",
      "F1 score at threshold 0.32 is 0.6801438848920863\n",
      "F1 score at threshold 0.33 is 0.6802612481857764\n",
      "F1 score at threshold 0.34 is 0.6802810715854194\n",
      "F1 score at threshold 0.35 is 0.6798313734191258\n",
      "F1 score at threshold 0.36 is 0.6787607316162747\n",
      "F1 score at threshold 0.37 is 0.6769578313253012\n",
      "F1 score at threshold 0.38 is 0.6762404072638857\n",
      "F1 score at threshold 0.39 is 0.676326280282122\n",
      "F1 score at threshold 0.4 is 0.6747640414668111\n",
      "F1 score at threshold 0.41 is 0.6740573034585058\n",
      "F1 score at threshold 0.42 is 0.6736111111111112\n",
      "F1 score at threshold 0.43 is 0.670328795478067\n",
      "F1 score at threshold 0.44 is 0.6682727053721995\n",
      "F1 score at threshold 0.45 is 0.6661800486618005\n",
      "F1 score at threshold 0.46 is 0.6627916496111339\n",
      "F1 score at threshold 0.47 is 0.6606656206127673\n",
      "F1 score at threshold 0.48 is 0.6558224891558226\n",
      "F1 score at threshold 0.49 is 0.6545057162071284\n",
      "F1 score at threshold 0.5 is 0.6507801899592944\n",
      "Best value [0.31, 0.680587229190422]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "cv_predictions = model.predict(cv_text, batch_size=512)\n",
    "\n",
    "thresholds = []\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    result = f1_score(cv_target, (cv_predictions>thresh).astype(int))\n",
    "    thresholds.append([thresh, result])\n",
    "    print(\"F1 score at threshold {} is {}\".format(thresh, result))\n",
    "\n",
    "thresholds.sort(key=lambda x: x[1], reverse=True)\n",
    "print(\"Best value {}\".format(thresholds[0]))\n",
    "best_thresh = thresholds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20803,
     "status": "ok",
     "timestamp": 1622310725645,
     "user": {
      "displayName": "Zhaoyi Huang",
      "photoUrl": "",
      "userId": "07120073316656133052"
     },
     "user_tz": 420
    },
    "id": "9LHDWU0GxVVu",
    "outputId": "9c3ebf62-8e72-4530-a302-508ee69cb29a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6751319069983185\n"
     ]
    }
   ],
   "source": [
    "#run on test set with best threshold\n",
    "total_predictions=model.predict(test_input_padded, batch_size=512)\n",
    "test_labels=list(test_data['target'])\n",
    "predictions1 = (total_predictions>best_thresh).astype(int)\n",
    "res=f1_score(test_labels, predictions1[:,0])\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPJErdv8Z4li7rO+lBZFjrG",
   "collapsed_sections": [],
   "mount_file_id": "1xpGRebfD3YCriVwqLrf1UHc1EpITmxst",
   "name": "BiLSTM_Keras_attention.ipynb",
   "provenance": [
    {
     "file_id": "13zP0BWAWKVQzY6HcIa-GCVNfN4Mr7jdF",
     "timestamp": 1621133190811
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
