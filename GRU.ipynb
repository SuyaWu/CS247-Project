{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRU.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "reHLNiQ70_jZ"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfYchzbk2ezH",
        "outputId": "707e08de-27b2-46d0-95d7-e9dc185ecaf7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38abFt4bibY4"
      },
      "source": [
        "train_data = pd.read_csv('/content/drive/Shareddrives/CS 247 project/data/splited_train.csv')\n",
        "test_data = pd.read_csv('/content/drive/Shareddrives/CS 247 project/data/splited_test.csv')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As7F7E6fjqUC"
      },
      "source": [
        "train_input = list(train_data['question_text'])\n",
        "train_label = list(train_data['target'])\n",
        "\n",
        "test_input = list(test_data['question_text'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7OD7O3ojudW",
        "outputId": "f8107f9a-3524-4f11-dc8d-7904a5219dbf"
      },
      "source": [
        "\n",
        "#remove all the stop words for the \n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop=stopwords.words('english') \n",
        "\n",
        "def remove_stop_words(x):\n",
        "    for word in stop:\n",
        "        token = \" \" + word + \" \"\n",
        "        if (x.find(token) != -1):\n",
        "            x = x.replace(token, \" \")\n",
        "    return x\n",
        "\n",
        "train_input_rsw = list(map(remove_stop_words, train_input))\n",
        "test_input_rsw = list(map(remove_stop_words, test_input))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWmBKPD1llau"
      },
      "source": [
        "max_features=100000\n",
        "embed_size = 300 \n",
        "max_length = 60 "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn5jUZJInZPx"
      },
      "source": [
        "def get_coefs(word,*arr): \n",
        "    return word, np.asarray(arr, dtype='float32')\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(\"/content/drive/Shareddrives/CS 247 project/data/embeddings/glove.840B.300d/glove.840B.300d.txt\",'r') as f:\n",
        "    for line in f:\n",
        "        \n",
        "        word,coefs=get_coefs(*line.split(\" \"))\n",
        "        #coefs = np.asarray(coefs, dtype='float32')\n",
        "        embeddings_index[word] = coefs"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp7o_4rvnhMh"
      },
      "source": [
        "tokenizer=Tokenizer(num_words=max_features)\n",
        "\n",
        "tokenizer.fit_on_texts(train_input_rsw)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "n_words=min(max_features,len(word_index))\n",
        "\n",
        "embedding_matrix = np.zeros((n_words+1, embed_size))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if i >= max_features: \n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None: \n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wusi8R48nB_o",
        "outputId": "b310f932-d30f-4d70-cfe7-e2952e59ed96"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(train_input_rsw)\n",
        "\n",
        "train_input_padded = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "print(train_input_padded.shape)\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(test_input_rsw)\n",
        "test_input_padded = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
        "print(test_input_padded.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1044897, 60)\n",
            "(261225, 60)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUclEQCBolmj"
      },
      "source": [
        "train_text, cv_text, train_target, cv_target = train_test_split(train_input_padded, train_label, test_size = 0.1, random_state=2)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTS6lJ_Zo2Ba"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding,Bidirectional,LSTM,Dropout,Conv1D,MaxPooling1D,Dense,GRU"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpC5AcyLo4Ku",
        "outputId": "d18277ca-0b5f-47b8-939f-e5d88c6708c5"
      },
      "source": [
        "gru=Sequential()\n",
        "gru.add(Embedding(n_words+1,embed_size,input_length=max_length,weights=[embedding_matrix], trainable=False))\n",
        "gru.add(Bidirectional(LSTM(256,return_sequences=True)))\n",
        "gru.add(Dropout(0.2))\n",
        "gru.add(Conv1D(100,5,activation='relu'))\n",
        "gru.add(MaxPooling1D(pool_size=4))\n",
        "gru.add(Bidirectional(GRU(128)))\n",
        "gru.add(Dropout(0.4))\n",
        "gru.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "gru.summary()\n",
        "\n",
        "gru.compile(loss='binary_crossentropy',optimizer='adam', metrics=['acc'])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 60, 300)           30000300  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 60, 512)           1140736   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 60, 512)           0         \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 56, 100)           256100    \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 14, 100)           0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 256)               176640    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 31,574,033\n",
            "Trainable params: 1,573,733\n",
            "Non-trainable params: 30,000,300\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIBvkjWGqzQH"
      },
      "source": [
        "# del embeddings_index\n",
        "# import gc\n",
        "# gc.collect()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEdAmpA6q1aF",
        "outputId": "daaa56de-83fa-49a2-8eea-b4929f3744b1"
      },
      "source": [
        "history=gru.fit(np.array(train_text), np.array(train_target), epochs = 5, validation_data=(np.array(cv_text),np.array(cv_target)), batch_size=1024,verbose=1)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "919/919 [==============================] - 253s 216ms/step - loss: 0.1418 - acc: 0.9437 - val_loss: 0.1086 - val_acc: 0.9576\n",
            "Epoch 2/5\n",
            "919/919 [==============================] - 201s 219ms/step - loss: 0.1056 - acc: 0.9578 - val_loss: 0.1037 - val_acc: 0.9590\n",
            "Epoch 3/5\n",
            "919/919 [==============================] - 201s 218ms/step - loss: 0.0986 - acc: 0.9606 - val_loss: 0.1049 - val_acc: 0.9572\n",
            "Epoch 4/5\n",
            "919/919 [==============================] - 200s 217ms/step - loss: 0.0925 - acc: 0.9627 - val_loss: 0.1022 - val_acc: 0.9601\n",
            "Epoch 5/5\n",
            "919/919 [==============================] - 197s 214ms/step - loss: 0.0843 - acc: 0.9657 - val_loss: 0.1054 - val_acc: 0.9592\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXVFNv80xJ9A",
        "outputId": "5d215420-23bf-457e-d66b-01a338b31823"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "cv_predictions = gru.predict(cv_text, batch_size=512)\n",
        "\n",
        "thresholds = []\n",
        "for thresh in np.arange(0.1, 0.501, 0.01):\n",
        "    thresh = np.round(thresh, 2)\n",
        "    result = f1_score(cv_target, (cv_predictions>thresh).astype(int))\n",
        "    thresholds.append([thresh, result])\n",
        "    print(\"F1 score at threshold {} is {}\".format(thresh, result))\n",
        "\n",
        "thresholds.sort(key=lambda x: x[1], reverse=True)\n",
        "print(\"Best value {}\".format(thresholds[0]))\n",
        "best_thresh = thresholds[0]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score at threshold 0.1 is 0.6222097272982849\n",
            "F1 score at threshold 0.11 is 0.6284666513866606\n",
            "F1 score at threshold 0.12 is 0.6337429386756741\n",
            "F1 score at threshold 0.13 is 0.6374327758406714\n",
            "F1 score at threshold 0.14 is 0.6413735142273983\n",
            "F1 score at threshold 0.15 is 0.6452359208523593\n",
            "F1 score at threshold 0.16 is 0.6475955610357583\n",
            "F1 score at threshold 0.17 is 0.650302916744738\n",
            "F1 score at threshold 0.18 is 0.6523908786558019\n",
            "F1 score at threshold 0.19 is 0.6549677748707804\n",
            "F1 score at threshold 0.2 is 0.6565259426361586\n",
            "F1 score at threshold 0.21 is 0.6584523111024186\n",
            "F1 score at threshold 0.22 is 0.6602069738316524\n",
            "F1 score at threshold 0.23 is 0.6617813603357537\n",
            "F1 score at threshold 0.24 is 0.6639730639730639\n",
            "F1 score at threshold 0.25 is 0.6649901447699312\n",
            "F1 score at threshold 0.26 is 0.6650212532565474\n",
            "F1 score at threshold 0.27 is 0.664917127071823\n",
            "F1 score at threshold 0.28 is 0.6662026726057906\n",
            "F1 score at threshold 0.29 is 0.6662452591656132\n",
            "F1 score at threshold 0.3 is 0.6657697210026908\n",
            "F1 score at threshold 0.31 is 0.6669994295493441\n",
            "F1 score at threshold 0.32 is 0.6665707916876393\n",
            "F1 score at threshold 0.33 is 0.6673916195447296\n",
            "F1 score at threshold 0.34 is 0.667007448517599\n",
            "F1 score at threshold 0.35 is 0.6662744521253127\n",
            "F1 score at threshold 0.36 is 0.6664691943127963\n",
            "F1 score at threshold 0.37 is 0.6648753545305269\n",
            "F1 score at threshold 0.38 is 0.6646098276770261\n",
            "F1 score at threshold 0.39 is 0.6638865721434528\n",
            "F1 score at threshold 0.4 is 0.6625353836737816\n",
            "F1 score at threshold 0.41 is 0.6625558809927548\n",
            "F1 score at threshold 0.42 is 0.6613855234544889\n",
            "F1 score at threshold 0.43 is 0.660926737633062\n",
            "F1 score at threshold 0.44 is 0.6601039533784848\n",
            "F1 score at threshold 0.45 is 0.658778686571905\n",
            "F1 score at threshold 0.46 is 0.65696\n",
            "F1 score at threshold 0.47 is 0.6550500161342369\n",
            "F1 score at threshold 0.48 is 0.6530114606193611\n",
            "F1 score at threshold 0.49 is 0.6504305043050431\n",
            "F1 score at threshold 0.5 is 0.6481037759233247\n",
            "Best value [0.33, 0.6673916195447296]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LHDWU0GxVVu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e0da652-8c4b-443c-dbf9-597cf74eea33"
      },
      "source": [
        "#run on test set with best threshold\n",
        "total_predictions=gru.predict(test_input_padded, batch_size=512)\n",
        "test_labels=list(test_data['target'])\n",
        "predictions1 = (total_predictions>best_thresh).astype(int)\n",
        "res=f1_score(test_labels, predictions1[:,0])\n",
        "print(res)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6633319602189136\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}