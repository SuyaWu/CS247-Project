{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-zODHvk97Qz"
   },
   "source": [
    "So, this is just a blend of the best models we have. But if we can do it better given different embeddings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 275,
     "status": "ok",
     "timestamp": 1622226169953,
     "user": {
      "displayName": "Zhaoyi Huang",
      "photoUrl": "",
      "userId": "07120073316656133052"
     },
     "user_tz": 420
    },
    "id": "9yafr7Hk9tYw"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 5031,
     "status": "ok",
     "timestamp": 1622226176197,
     "user": {
      "displayName": "Zhaoyi Huang",
      "photoUrl": "",
      "userId": "07120073316656133052"
     },
     "user_tz": 420
    },
    "id": "liT0X39rArHV"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./data/splited_train.csv')\n",
    "test_data = pd.read_csv('./data/splited_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1622226176410,
     "user": {
      "displayName": "Zhaoyi Huang",
      "photoUrl": "",
      "userId": "07120073316656133052"
     },
     "user_tz": 420
    },
    "id": "rdlHNjf9AsjU"
   },
   "outputs": [],
   "source": [
    "train_input = list(train_data['question_text'])\n",
    "train_label = list(train_data['target'])\n",
    "\n",
    "test_input = list(test_data['question_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1622226176410,
     "user": {
      "displayName": "Zhaoyi Huang",
      "photoUrl": "",
      "userId": "07120073316656133052"
     },
     "user_tz": 420
    },
    "id": "fYT2ojAjAuZx"
   },
   "outputs": [],
   "source": [
    "train_input_rsw=train_input\n",
    "test_input_rsw=test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1622226176411,
     "user": {
      "displayName": "Zhaoyi Huang",
      "photoUrl": "",
      "userId": "07120073316656133052"
     },
     "user_tz": 420
    },
    "id": "E9IeOMslA075"
   },
   "outputs": [],
   "source": [
    "max_features=95000\n",
    "embed_size = 300 \n",
    "max_length = 70 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 150484,
     "status": "ok",
     "timestamp": 1622226326889,
     "user": {
      "displayName": "Zhaoyi Huang",
      "photoUrl": "",
      "userId": "07120073316656133052"
     },
     "user_tz": 420
    },
    "id": "R9SjhyV8A2Dn"
   },
   "outputs": [],
   "source": [
    "def get_coefs(word,*arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(\"./data/embeddings/glove.840B.300d/glove.840B.300d.txt\",'r') as f:\n",
    "    for line in f:\n",
    "        \n",
    "        word,coefs=get_coefs(*line.split(\" \"))\n",
    "        #coefs = np.asarray(coefs, dtype='float32')\n",
    "        embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26924,
     "status": "ok",
     "timestamp": 1622226353809,
     "user": {
      "displayName": "Zhaoyi Huang",
      "photoUrl": "",
      "userId": "07120073316656133052"
     },
     "user_tz": 420
    },
    "id": "amFD7GDnCuqU",
    "outputId": "d08a55fb-e17a-4157-9cf3-d0e7f821467e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "tokenizer=Tokenizer(num_words=max_features)\n",
    "\n",
    "tokenizer.fit_on_texts(train_input_rsw)\n",
    "\n",
    "\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "n_words=min(max_features,len(word_index))\n",
    "\n",
    "# embedding_matrix = np.zeros((n_words+1, embed_size))\n",
    "\n",
    "# for word, i in word_index.items():\n",
    "#     if i >= max_features: \n",
    "#         continue\n",
    "#     embedding_vector = embeddings_index.get(word)\n",
    "#     if embedding_vector is not None: \n",
    "#         embedding_matrix[i] = embedding_vector\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26587,
     "status": "ok",
     "timestamp": 1622226380383,
     "user": {
      "displayName": "Zhaoyi Huang",
      "photoUrl": "",
      "userId": "07120073316656133052"
     },
     "user_tz": 420
    },
    "id": "dVwMf6fdCzQy",
    "outputId": "89318196-f98c-46c2-9139-ed10c2b2374d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1044897, 70)\n",
      "(261225, 70)\n"
     ]
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(train_input_rsw)\n",
    "\n",
    "train_input_padded = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "print(train_input_padded.shape)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(test_input_rsw)\n",
    "test_input_padded = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n",
    "print(test_input_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1622226380383,
     "user": {
      "displayName": "Zhaoyi Huang",
      "photoUrl": "",
      "userId": "07120073316656133052"
     },
     "user_tz": 420
    },
    "id": "EXdUIhDHC3MP"
   },
   "outputs": [],
   "source": [
    "train_text, cv_text, train_target, cv_target = train_test_split(train_input_padded, train_label, test_size = 0.1, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1622226380386,
     "user": {
      "displayName": "Zhaoyi Huang",
      "photoUrl": "",
      "userId": "07120073316656133052"
     },
     "user_tz": 420
    },
    "id": "5NdUMnSSC34e"
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/qqgeogor/keras-lstm-attention-glove840b-lb-0-043\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "        self.W = self.add_weight(shape=(input_shape[-1],),\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 initializer=self.init,\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight(shape=(input_shape[1],),\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     initializer='zero',\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1622226380386,
     "user": {
      "displayName": "Zhaoyi Huang",
      "photoUrl": "",
      "userId": "07120073316656133052"
     },
     "user_tz": 420
    },
    "id": "7A1FP4b4D21H"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding,Bidirectional,LSTM,Dropout,Conv1D,MaxPooling1D,Dense\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 5514,
     "status": "ok",
     "timestamp": 1622226386247,
     "user": {
      "displayName": "Zhaoyi Huang",
      "photoUrl": "",
      "userId": "07120073316656133052"
     },
     "user_tz": 420
    },
    "id": "7c9f-LhpEYCc"
   },
   "outputs": [],
   "source": [
    "inp = Input(shape=(max_length,))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "x=Dropout(0.4)(x)\n",
    "x = Attention(max_length)(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=1e-3), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 340451,
     "status": "ok",
     "timestamp": 1622226726684,
     "user": {
      "displayName": "Zhaoyi Huang",
      "photoUrl": "",
      "userId": "07120073316656133052"
     },
     "user_tz": 420
    },
    "id": "cza8-z7mEZoA",
    "outputId": "00aa2d3e-00f5-4d8b-f5ac-fef9e475dc68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "919/919 [==============================] - 91s 70ms/step - loss: 0.1479 - acc: 0.9414 - val_loss: 0.1109 - val_acc: 0.9563\n",
      "Epoch 2/5\n",
      "919/919 [==============================] - 62s 67ms/step - loss: 0.1084 - acc: 0.9572 - val_loss: 0.1073 - val_acc: 0.9574\n",
      "Epoch 3/5\n",
      "919/919 [==============================] - 62s 68ms/step - loss: 0.1009 - acc: 0.9597 - val_loss: 0.1021 - val_acc: 0.9591\n",
      "Epoch 4/5\n",
      "919/919 [==============================] - 62s 68ms/step - loss: 0.0953 - acc: 0.9619 - val_loss: 0.1004 - val_acc: 0.9604\n",
      "Epoch 5/5\n",
      "919/919 [==============================] - 62s 68ms/step - loss: 0.0907 - acc: 0.9635 - val_loss: 0.1002 - val_acc: 0.9602\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(np.array(train_text), np.array(train_target), epochs =5, validation_data=(np.array(cv_text),np.array(cv_target)), batch_size=1024,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 5311,
     "status": "ok",
     "timestamp": 1622226731984,
     "user": {
      "displayName": "Zhaoyi Huang",
      "photoUrl": "",
      "userId": "07120073316656133052"
     },
     "user_tz": 420
    },
    "id": "Zknhiub2EcQH"
   },
   "outputs": [],
   "source": [
    "pred_glove=model.predict(cv_text, batch_size=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 9536,
     "status": "ok",
     "timestamp": 1622226741517,
     "user": {
      "displayName": "Zhaoyi Huang",
      "photoUrl": "",
      "userId": "07120073316656133052"
     },
     "user_tz": 420
    },
    "id": "Ez2YFLreL70j"
   },
   "outputs": [],
   "source": [
    "pred_glove_test=model.predict(test_input_padded, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQQXC0F2Ez41"
   },
   "source": [
    "Do another embedding with wiki news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79721,
     "status": "ok",
     "timestamp": 1622226821225,
     "user": {
      "displayName": "Zhaoyi Huang",
      "photoUrl": "",
      "userId": "07120073316656133052"
     },
     "user_tz": 420
    },
    "id": "IVVe_HP1E1xI",
    "outputId": "5c1243be-b9d8-4479-b220-156e0ba2081b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2822: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_FILE = './data/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o)>100)\n",
    "\n",
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "for word, i in word_index.items():\n",
    "    if i >= max_features: continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 386,
     "status": "ok",
     "timestamp": 1622226821607,
     "user": {
      "displayName": "Zhaoyi Huang",
      "photoUrl": "",
      "userId": "07120073316656133052"
     },
     "user_tz": 420
    },
    "id": "atjfAhEbFBxk"
   },
   "outputs": [],
   "source": [
    "#need to write the model again as embedding matrix changes\n",
    "inp = Input(shape=(max_length,))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True))(x)\n",
    "x=Dropout(0.4)(x)\n",
    "x = Attention(max_length)(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "x = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=1e-3), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 326504,
     "status": "ok",
     "timestamp": 1622227148109,
     "user": {
      "displayName": "Zhaoyi Huang",
      "photoUrl": "",
      "userId": "07120073316656133052"
     },
     "user_tz": 420
    },
    "id": "KsIHB3LkGcG8",
    "outputId": "a534c9e4-f5d9-4fdb-c64e-97f1fc475bbd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "919/919 [==============================] - 72s 71ms/step - loss: 0.1601 - acc: 0.9394 - val_loss: 0.1159 - val_acc: 0.9548\n",
      "Epoch 2/5\n",
      "919/919 [==============================] - 63s 69ms/step - loss: 0.1144 - acc: 0.9547 - val_loss: 0.1097 - val_acc: 0.9569\n",
      "Epoch 3/5\n",
      "919/919 [==============================] - 63s 69ms/step - loss: 0.1079 - acc: 0.9574 - val_loss: 0.1077 - val_acc: 0.9570\n",
      "Epoch 4/5\n",
      "919/919 [==============================] - 63s 69ms/step - loss: 0.1032 - acc: 0.9592 - val_loss: 0.1045 - val_acc: 0.9589\n",
      "Epoch 5/5\n",
      "919/919 [==============================] - 63s 69ms/step - loss: 0.1012 - acc: 0.9600 - val_loss: 0.1027 - val_acc: 0.9595\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(np.array(train_text), np.array(train_target), epochs =5, validation_data=(np.array(cv_text),np.array(cv_target)), batch_size=1024,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 7460,
     "status": "ok",
     "timestamp": 1622227155561,
     "user": {
      "displayName": "Zhaoyi Huang",
      "photoUrl": "",
      "userId": "07120073316656133052"
     },
     "user_tz": 420
    },
    "id": "BKSRTm43GeQ5"
   },
   "outputs": [],
   "source": [
    "pred_wiki=model.predict(cv_text, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 8728,
     "status": "ok",
     "timestamp": 1622227164287,
     "user": {
      "displayName": "Zhaoyi Huang",
      "photoUrl": "",
      "userId": "07120073316656133052"
     },
     "user_tz": 420
    },
    "id": "yYUpWgKUMCs3"
   },
   "outputs": [],
   "source": [
    "pred_wiki_test=model.predict(test_input_padded, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3403,
     "status": "ok",
     "timestamp": 1622228861686,
     "user": {
      "displayName": "Zhaoyi Huang",
      "photoUrl": "",
      "userId": "07120073316656133052"
     },
     "user_tz": 420
    },
    "id": "uv6g3ttEG8Ct",
    "outputId": "944990d3-2102-43f3-b31e-b91fc0850610"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold 0.1 is 0.6033519553072626\n",
      "F1 score at threshold 0.11 is 0.6138942410618711\n",
      "F1 score at threshold 0.12 is 0.6210065645514223\n",
      "F1 score at threshold 0.13 is 0.6283930661613064\n",
      "F1 score at threshold 0.14 is 0.6351819265482205\n",
      "F1 score at threshold 0.15 is 0.6411842942230961\n",
      "F1 score at threshold 0.16 is 0.6459372249926664\n",
      "F1 score at threshold 0.17 is 0.6500268064573778\n",
      "F1 score at threshold 0.18 is 0.6537740980238109\n",
      "F1 score at threshold 0.19 is 0.6590700238926668\n",
      "F1 score at threshold 0.2 is 0.662114346017754\n",
      "F1 score at threshold 0.21 is 0.665618316769405\n",
      "F1 score at threshold 0.22 is 0.668281489036206\n",
      "F1 score at threshold 0.23 is 0.6710458526532715\n",
      "F1 score at threshold 0.24 is 0.6731885475771212\n",
      "F1 score at threshold 0.25 is 0.6764317761942465\n",
      "F1 score at threshold 0.26 is 0.6782666666666667\n",
      "F1 score at threshold 0.27 is 0.6791638570465273\n",
      "F1 score at threshold 0.28 is 0.6795772246846233\n",
      "F1 score at threshold 0.29 is 0.6807070846568154\n",
      "F1 score at threshold 0.3 is 0.681472169844263\n",
      "F1 score at threshold 0.31 is 0.6815902831720924\n",
      "F1 score at threshold 0.32 is 0.6822236494683507\n",
      "F1 score at threshold 0.33 is 0.6821025382900697\n",
      "F1 score at threshold 0.34 is 0.6838203227213258\n",
      "F1 score at threshold 0.35 is 0.6830593071051086\n",
      "F1 score at threshold 0.36 is 0.6818013205727428\n",
      "F1 score at threshold 0.37 is 0.6805929919137467\n",
      "F1 score at threshold 0.38 is 0.6795046065549012\n",
      "F1 score at threshold 0.39 is 0.6786805131337812\n",
      "F1 score at threshold 0.4 is 0.6773399014778325\n",
      "F1 score at threshold 0.41 is 0.6774293697609437\n",
      "F1 score at threshold 0.42 is 0.6748629600626469\n",
      "F1 score at threshold 0.43 is 0.6731422253810314\n",
      "F1 score at threshold 0.44 is 0.6705488194001276\n",
      "F1 score at threshold 0.45 is 0.6698826177842098\n",
      "F1 score at threshold 0.46 is 0.6687231106420976\n",
      "F1 score at threshold 0.47 is 0.6665573770491804\n",
      "F1 score at threshold 0.48 is 0.6630785791173305\n",
      "F1 score at threshold 0.49 is 0.6593608833863142\n",
      "F1 score at threshold 0.5 is 0.6555330634278003\n",
      "Best value [0.34, 0.6838203227213258]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "pred_total=pred_wiki*0.5+pred_glove*0.5\n",
    "thresholds = []\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    result = f1_score(cv_target, (pred_total>thresh).astype(int))\n",
    "    thresholds.append([thresh, result])\n",
    "    print(\"F1 score at threshold {} is {}\".format(thresh, result))\n",
    "\n",
    "thresholds.sort(key=lambda x: x[1], reverse=True)\n",
    "print(\"Best value {}\".format(thresholds[0]))\n",
    "best_thresh = thresholds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 380,
     "status": "ok",
     "timestamp": 1622228862063,
     "user": {
      "displayName": "Zhaoyi Huang",
      "photoUrl": "",
      "userId": "07120073316656133052"
     },
     "user_tz": 420
    },
    "id": "ORfh_IKXL1P2",
    "outputId": "ba511b45-2a9f-488a-86de-9f957b76ea21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6813322368421052\n"
     ]
    }
   ],
   "source": [
    "total_predictions=pred_wiki_test*0.5+pred_glove_test*0.5\n",
    "test_labels=list(test_data['target'])\n",
    "predictions1 = (total_predictions>best_thresh).astype(int)\n",
    "res=f1_score(test_labels, predictions1[:,0])\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMD0zzLuvAUkQWYCggp1sO0",
   "machine_shape": "hm",
   "mount_file_id": "1JqmuKywsf3CFl-6OqIjGUzyp02oG5mo5",
   "name": "blending_embeddings_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
